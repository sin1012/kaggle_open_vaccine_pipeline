{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "open_vaccine_training_pipeline_sin.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-hnbmaXoLeG"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fGGZBHoWPVF",
        "outputId": "5391c672-3701-47cf-db74-0882be3d2f07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Oct  1 01:27:05 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    40W / 300W |   2943MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlS-9tW4d36S",
        "outputId": "17e984c9-bebe-48ee-f767-3e4d1bcf7133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## colab only\n",
        "! mkdir -p ~/.kaggle/\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! kaggle competitions download stanford-covid-vaccine  \n",
        "! unzip train.json.zip\n",
        "! unzip test.json.zip\n",
        "! unzip sample_submission.csv.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading id_008d87c43.npy to /content\n",
            "  0% 0.00/132k [00:00<?, ?B/s]\n",
            "100% 132k/132k [00:00<00:00, 50.6MB/s]\n",
            "Downloading id_0082d463b.npy to /content\n",
            "  0% 0.00/89.6k [00:00<?, ?B/s]\n",
            "100% 89.6k/89.6k [00:00<00:00, 93.5MB/s]\n",
            "Downloading id_006af2226.npy to /content\n",
            "  0% 0.00/132k [00:00<?, ?B/s]\n",
            "100% 132k/132k [00:00<00:00, 43.0MB/s]\n",
            "Downloading id_00583aef6.npy to /content\n",
            "  0% 0.00/132k [00:00<?, ?B/s]\n",
            "100% 132k/132k [00:00<00:00, 43.2MB/s]\n",
            "Downloading id_006f36f57.npy to /content\n",
            "  0% 0.00/89.6k [00:00<?, ?B/s]\n",
            "100% 89.6k/89.6k [00:00<00:00, 84.5MB/s]\n",
            "Downloading id_001f94081.npy to /content\n",
            "  0% 0.00/89.6k [00:00<?, ?B/s]\n",
            "100% 89.6k/89.6k [00:00<00:00, 92.0MB/s]\n",
            "Downloading id_0031191b7.npy to /content\n",
            "  0% 0.00/132k [00:00<?, ?B/s]\n",
            "100% 132k/132k [00:00<00:00, 43.1MB/s]\n",
            "Downloading id_00073f8be.npy to /content\n",
            "  0% 0.00/89.6k [00:00<?, ?B/s]\n",
            "100% 89.6k/89.6k [00:00<00:00, 92.2MB/s]\n",
            "Downloading id_002852873.npy to /content\n",
            "  0% 0.00/132k [00:00<?, ?B/s]\n",
            "100% 132k/132k [00:00<00:00, 41.4MB/s]\n",
            "Downloading id_0087940f4.npy to /content\n",
            "  0% 0.00/89.6k [00:00<?, ?B/s]\n",
            "100% 89.6k/89.6k [00:00<00:00, 91.0MB/s]\n",
            "Downloading id_000ae4237.npy to /content\n",
            "  0% 0.00/132k [00:00<?, ?B/s]\n",
            "100% 132k/132k [00:00<00:00, 41.4MB/s]\n",
            "Downloading id_0051b1d76.npy to /content\n",
            "  0% 0.00/132k [00:00<?, ?B/s]\n",
            "100% 132k/132k [00:00<00:00, 125MB/s]\n",
            "Downloading id_0020473f7.npy to /content\n",
            "  0% 0.00/132k [00:00<?, ?B/s]\n",
            "100% 132k/132k [00:00<00:00, 120MB/s]\n",
            "Downloading id_00131c573.npy to /content\n",
            "  0% 0.00/89.6k [00:00<?, ?B/s]\n",
            "100% 89.6k/89.6k [00:00<00:00, 92.1MB/s]\n",
            "Downloading id_006a0ab6e.npy to /content\n",
            "  0% 0.00/132k [00:00<?, ?B/s]\n",
            "100% 132k/132k [00:00<00:00, 44.9MB/s]\n",
            "Downloading id_00181fd34.npy to /content\n",
            "  0% 0.00/89.6k [00:00<?, ?B/s]\n",
            "100% 89.6k/89.6k [00:00<00:00, 93.3MB/s]\n",
            "Downloading id_003ab2445.npy to /content\n",
            "  0% 0.00/132k [00:00<?, ?B/s]\n",
            "100% 132k/132k [00:00<00:00, 119MB/s]\n",
            "Downloading id_0088b606f.npy to /content\n",
            "  0% 0.00/132k [00:00<?, ?B/s]\n",
            "100% 132k/132k [00:00<00:00, 132MB/s]\n",
            "Downloading id_0049f53ba.npy to /content\n",
            "  0% 0.00/89.6k [00:00<?, ?B/s]\n",
            "100% 89.6k/89.6k [00:00<00:00, 81.5MB/s]\n",
            "Downloading id_00710bcba.npy to /content\n",
            "  0% 0.00/132k [00:00<?, ?B/s]\n",
            "100% 132k/132k [00:00<00:00, 136MB/s]\n",
            "Downloading test.json.zip to /content\n",
            "  0% 0.00/286k [00:00<?, ?B/s]\n",
            "100% 286k/286k [00:00<00:00, 87.7MB/s]\n",
            "Downloading train.json.zip to /content\n",
            "  0% 0.00/3.80M [00:00<?, ?B/s]\n",
            "100% 3.80M/3.80M [00:00<00:00, 127MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.00M [00:00<?, ?B/s]\n",
            "100% 1.00M/1.00M [00:00<00:00, 67.9MB/s]\n",
            "Archive:  train.json.zip\n",
            "  inflating: train.json              \n",
            "Archive:  test.json.zip\n",
            "  inflating: test.json               \n",
            "Archive:  sample_submission.csv.zip\n",
            "  inflating: sample_submission.csv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2MES6rC24cR"
      },
      "source": [
        "reset -fs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzWFKfQsNwwD"
      },
      "source": [
        "## use one-hot input?\n",
        "one_hot = False\n",
        "\n",
        "## filter noisy labels?\n",
        "filter = True\n",
        "\n",
        "## add additional feature 'pairs'\n",
        "## if use one_hot, then you cannot add pairs\n",
        "add_pairs = True\n",
        "\n",
        "## feature engineering, add 3 features\n",
        "feature_engineering = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eL9xTX3ejlq"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Basic data manipulation libraries\n",
        "import pandas as pd, numpy as np\n",
        "import math, json, gc, random, os, sys\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "#Deep Learning Libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras.layers as L\n",
        "\n",
        "#Library for model evaluation\n",
        "from sklearn.model_selection import train_test_split, KFold, RepeatedStratifiedKFold, StratifiedKFold, GroupKFold\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "from time import time\n",
        "from scipy.optimize import minimize, fsolve\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A1lioLafNOy"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO8uURGfe3fr"
      },
      "source": [
        "train = pd.read_json('train.json', lines=True)\n",
        "test = pd.read_json('test.json', lines=True)\n",
        "train = train.query('signal_to_noise >= 1')\n",
        "# additional features\n",
        "\n",
        "# def read_bpps_sum(df):\n",
        "#     bpps_arr = []\n",
        "#     for mol_id in df.id.to_list():\n",
        "#         bpps_arr.append(np.load(f\"/content/drive/My Drive/bpps/{mol_id}.npy\").max(axis=1))\n",
        "#     return bpps_arr\n",
        "\n",
        "# def read_bpps_max(df):\n",
        "#     bpps_arr = []\n",
        "#     for mol_id in df.id.to_list():\n",
        "#         bpps_arr.append(np.load(f\"/content/drive/My Drive/bpps/{mol_id}.npy\").sum(axis=1))\n",
        "#     return bpps_arr\n",
        "\n",
        "# def read_bpps_nb(df):\n",
        "#     # normalized non-zero number\n",
        "#     # from https://www.kaggle.com/symyksr/openvaccine-deepergcn \n",
        "#     bpps_nb_mean = 0.077522 # mean of bpps_nb across all training data\n",
        "#     bpps_nb_std = 0.08914   # std of bpps_nb across all training data\n",
        "#     bpps_arr = []\n",
        "#     for mol_id in df.id.to_list():\n",
        "#         bpps = np.load(f\"/content/drive/My Drive/bpps/{mol_id}.npy\")\n",
        "#         bpps_nb = (bpps > 0).sum(axis=0) / bpps.shape[0]\n",
        "#         bpps_nb = (bpps_nb - bpps_nb_mean) / bpps_nb_std\n",
        "#         bpps_arr.append(bpps_nb)\n",
        "#     return bpps_arr \n",
        "\n",
        "# if feature_engineering:\n",
        "#   train['bpps_sum'] = read_bpps_sum(train)\n",
        "#   test['bpps_sum'] = read_bpps_sum(test)\n",
        "#   train['bpps_max'] = read_bpps_max(train)\n",
        "#   test['bpps_max'] = read_bpps_max(test)\n",
        "#   train['bpps_nb'] = read_bpps_nb(train)\n",
        "#   test['bpps_nb'] = read_bpps_nb(test)\n",
        "\n",
        "sample_sub = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "target_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n",
        "\n",
        "token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n",
        "\n",
        "def preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n",
        "    return np.transpose(\n",
        "        np.array(df[cols].applymap(lambda seq: [token2int[x] for x in seq]).values.tolist()),\n",
        "        (0, 2, 1))\n",
        "\n",
        "def fe_preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n",
        "    base_fea = np.transpose(\n",
        "        np.array(\n",
        "            df[cols]\n",
        "            .applymap(lambda seq: [token2int[x] for x in seq])\n",
        "            .values\n",
        "            .tolist()\n",
        "        ),\n",
        "        (0, 2, 1)\n",
        "    )\n",
        "    bpps_sum_fea = np.array(df['bpps_sum'].to_list())[:,:,np.newaxis]\n",
        "    bpps_max_fea = np.array(df['bpps_max'].to_list())[:,:,np.newaxis]\n",
        "    bpps_nb_fea = np.array(df['bpps_nb'].to_list())[:,:,np.newaxis]\n",
        "    return np.concatenate([base_fea,bpps_sum_fea,bpps_max_fea,bpps_nb_fea], 2)\n",
        "\n",
        "# if feature_engineering:\n",
        "#   if filter:\n",
        "#     train_inputs = fe_preprocess_inputs(train[train.signal_to_noise >= 1])\n",
        "#     train_labels = np.array(train[train.signal_to_noise >= 1][target_cols].values.tolist()).transpose((0, 2, 1))\n",
        "#     train = train.query('signal_to_noise >= 1')\n",
        "#   else:\n",
        "#     train_inputs = preprocess_inputs(train)\n",
        "#     train_labels = np.array(train[target_cols].values.tolist()).transpose((0, 2, 1))\n",
        "# else:\n",
        "#   if filter:\n",
        "#     train_inputs = preprocess_inputs(train[train.signal_to_noise >= 1])\n",
        "#     train_labels = np.array(train[train.signal_to_noise >= 1][target_cols].values.tolist()).transpose((0, 2, 1))\n",
        "#     train = train.query('signal_to_noise >= 1')\n",
        "#   else:\n",
        "#     train_inputs = preprocess_inputs(train)\n",
        "#     train_labels = np.array(train[target_cols].values.tolist()).transpose((0, 2, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnGl3ARJNqie"
      },
      "source": [
        "# def to_one_hot(dim3):\n",
        "#     dim14 = np.zeros(14)\n",
        "#     for num in dim3:\n",
        "#         dim14[num] = 1\n",
        "#     return dim14\n",
        "# if one_hot:\n",
        "#     train_inputs = np.apply_along_axis(to_one_hot, 2, train_inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pLSrWQuanMU"
      },
      "source": [
        "# def compute_base_pairings(arr, public=True):\n",
        "#     if public:\n",
        "#         pairings = np.zeros((len(arr), 107), dtype=np.int8)\n",
        "#     else:\n",
        "#         pairings = np.zeros((len(arr), 130), dtype=np.int8)\n",
        "    \n",
        "#     for i in range(len(arr)):\n",
        "#         temp_struc = arr[i, :, 1]\n",
        "#         temp_nucle = arr[i, :, 0]\n",
        "#         temp = np.zeros(len(temp_struc), dtype=np.int8)\n",
        "#         temp_pair = np.zeros(len(temp_struc), dtype=np.int8)\n",
        "        \n",
        "#         p = []\n",
        "#         count = 0\n",
        "        \n",
        "#         # map pairings to same integer\n",
        "#         for j in range(len(temp_struc)):\n",
        "#             if temp_struc[j] == 0:\n",
        "#                 count += 1\n",
        "#                 p.append(count)\n",
        "#                 temp[j] = count\n",
        "#             elif temp_struc[j] == 1:\n",
        "#                 temp[j] = p.pop()\n",
        "        \n",
        "#         # map pair nucleotide\n",
        "#         for j in range(1, count+1):\n",
        "#             pair_idx = np.where(temp==j)[0]\n",
        "            \n",
        "#             if len(pair_idx) > 1:\n",
        "#                 temp_pair[pair_idx[0]] = temp_nucle[pair_idx[1]]\n",
        "#                 temp_pair[pair_idx[1]] = temp_nucle[pair_idx[0]]\n",
        "#             else:\n",
        "#                 temp_pair[pair_idx[0]] = 3\n",
        "    \n",
        "#         pairings[i] = temp_pair\n",
        "    \n",
        "#     return pairings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUBNkP2qbK2S"
      },
      "source": [
        "# #get different test sets and process each\n",
        "public_df = test.query(\"seq_length == 107\").copy()\n",
        "private_df = test.query(\"seq_length == 130\").copy()\n",
        "# if feature_engineering:\n",
        "#   public_inputs = fe_preprocess_inputs(public_df)\n",
        "#   private_inputs = fe_preprocess_inputs(private_df)\n",
        "# else:\n",
        "#   public_inputs = preprocess_inputs(public_df)\n",
        "#   private_inputs = preprocess_inputs(private_df)\n",
        "\n",
        "# if one_hot:\n",
        "#   public_inputs = np.apply_along_axis(to_one_hot, 2, public_inputs)\n",
        "#   private_inputs = np.apply_along_axis(to_one_hot, 2, private_inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYCWZTWxatwm"
      },
      "source": [
        "# if add_pairs:\n",
        "#   train_pairs = compute_base_pairings(train_inputs)\n",
        "#   public_test_pairs = compute_base_pairings(public_inputs)\n",
        "#   private_test_pairs = compute_base_pairings(private_inputs, public=False)\n",
        "#   train_inputs = np.concatenate((train_inputs, np.reshape(train_pairs, (train_pairs.shape[0], train_pairs.shape[1], 1))), axis=2)\n",
        "#   public_inputs = np.concatenate((public_inputs, np.reshape(public_test_pairs, (public_test_pairs.shape[0], public_test_pairs.shape[1], 1))), axis=2)\n",
        "#   private_inputs = np.concatenate((private_inputs, np.reshape(private_test_pairs, (private_test_pairs.shape[0], private_test_pairs.shape[1], 1))), axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlrX0QWVAmN7"
      },
      "source": [
        "train_inputs = np.load('/content/drive/My Drive/open_vaccine_data_added_fe/train_inputs.npy')\n",
        "train_labels = np.load('/content/drive/My Drive/open_vaccine_data_added_fe/train_labels.npy')\n",
        "private_inputs = np.load('/content/drive/My Drive/open_vaccine_data_added_fe/private_inputs.npy')\n",
        "public_inputs = np.load('/content/drive/My Drive/open_vaccine_data_added_fe/public_inputs.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdEP7JFNz2JR"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans_model = KMeans(n_clusters=200, random_state=42).fit(train_inputs[:,:,0])\n",
        "train['cluster_id'] = kmeans_model.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNH-xpdNWdlu"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl4a14ICWbh_"
      },
      "source": [
        "def rmse(y_actual, y_pred):\n",
        "    mse = tf.keras.losses.mean_squared_error(y_actual, y_pred)\n",
        "    return K.sqrt(mse)\n",
        "    \n",
        "def MCRMSE(y_actual, y_pred, num_scored=len(target_cols)):\n",
        "    score = 0\n",
        "    for i in [range(num_scored)]:\n",
        "        score += rmse(y_actual[:, :, i], y_pred[:, :, i]) / num_scored\n",
        "    return score\n",
        "\n",
        "def MCRMSE_3(y_actual, y_pred):\n",
        "    score = 0\n",
        "    for i in [0,1,2,3,4]:\n",
        "        score += rmse(y_actual[:, :, i], y_pred[:, :, i]) / 5\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV-siuElfC8I"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec1guEvRe5n5"
      },
      "source": [
        "def gru_layer(hidden_dim, dropout):\n",
        "    return tf.keras.layers.Bidirectional(\n",
        "                                tf.keras.layers.GRU(hidden_dim,\n",
        "                                dropout=dropout,\n",
        "                                return_sequences=True,\n",
        "                                kernel_initializer = 'orthogonal'))\n",
        "\n",
        "def lstm_layer(hidden_dim, dropout):\n",
        "    return tf.keras.layers.Bidirectional(\n",
        "                                tf.keras.layers.LSTM(hidden_dim,\n",
        "                                dropout=dropout,\n",
        "                                return_sequences=True,\n",
        "                                kernel_initializer = 'orthogonal'))\n",
        "\n",
        "def build_model(gru=1,seq_len=107, pred_len=68, dropout=0.4,\n",
        "                embed_dim=100, hidden_dim=128):\n",
        "    if one_hot:\n",
        "      inputs = tf.keras.layers.Input(shape=(seq_len, 14))\n",
        "    elif feature_engineering:\n",
        "      inputs = tf.keras.layers.Input(shape=(seq_len, 7))\n",
        "    elif add_pairs:\n",
        "      inputs = tf.keras.layers.Input(shape=(seq_len, 4))\n",
        "    else:\n",
        "      inputs = tf.keras.layers.Input(shape=(seq_len, 3))\n",
        "\n",
        "    embed = tf.keras.layers.Embedding(input_dim=len(token2int), output_dim=embed_dim)(inputs)\n",
        "    reshaped = tf.reshape(\n",
        "        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n",
        "    \n",
        "    #reshaped = tf.keras.layers.SpatialDropout1D(.2)(reshaped)\n",
        "    \n",
        "    if gru==0:\n",
        "        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        \n",
        "    elif gru==1:\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "        \n",
        "    elif gru==2:\n",
        "        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
        "        \n",
        "    elif gru==3:\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        \n",
        "    elif gru==4:\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n",
        "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
        "        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n",
        "    \n",
        "    #only making predictions on the first part of each sequence\n",
        "    truncated = hidden[:, :pred_len]\n",
        "    \n",
        "    out1 = tf.keras.layers.Dense(1024, activation='relu')(truncated)\n",
        "    out2 = tf.keras.layers.Dropout(0.4)(out1)\n",
        "    out = tf.keras.layers.Dense(5, activation='linear')(out2)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=out)\n",
        "\n",
        "    #some optimizers\n",
        "    adam = tf.optimizers.Adam()\n",
        "    radam = tfa.optimizers.RectifiedAdam()\n",
        "    lookahead = tfa.optimizers.Lookahead(adam, sync_period=6)\n",
        "    ranger = tfa.optimizers.Lookahead(radam, sync_period=6)\n",
        "    \n",
        "    model.compile(optimizer = adam, loss=MCRMSE_3)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYQDAu59fGNb"
      },
      "source": [
        "def build_wavenet_model(seq_len = 107, pred_len = 68, embed_dim = 100, dropout = 0.1):\n",
        "    \n",
        "    def wave_block(x, filters, kernel_size, n):\n",
        "        dilation_rates = [2 ** i for i in range(n)]\n",
        "        x = tf.keras.layers.Conv1D(filters = filters, \n",
        "                                   kernel_size = 1,\n",
        "                                   padding = 'same')(x)\n",
        "        res_x = x\n",
        "        for dilation_rate in dilation_rates:\n",
        "            tanh_out = tf.keras.layers.Conv1D(filters = filters,\n",
        "                              kernel_size = kernel_size,\n",
        "                              padding = 'same', \n",
        "                              activation = 'tanh', \n",
        "                              dilation_rate = dilation_rate)(x)\n",
        "            sigm_out = tf.keras.layers.Conv1D(filters = filters,\n",
        "                              kernel_size = kernel_size,\n",
        "                              padding = 'same',\n",
        "                              activation = 'sigmoid', \n",
        "                              dilation_rate = dilation_rate)(x)\n",
        "            x = tf.keras.layers.Multiply()([tanh_out, sigm_out])\n",
        "            x = tf.keras.layers.Conv1D(filters = filters,\n",
        "                       kernel_size = 1,\n",
        "                       padding = 'same')(x)\n",
        "            res_x = tf.keras.layers.Add()([res_x, x])\n",
        "        return res_x\n",
        "    if one_hot:\n",
        "      inputs = tf.keras.layers.Input(shape = (seq_len, 14))\n",
        "    elif feature_engineering:\n",
        "      inputs = tf.keras.layers.Input(shape = (seq_len, 7))\n",
        "    elif add_pairs:\n",
        "      inputs = tf.keras.layers.Input(shape = (seq_len, 4))\n",
        "    else:\n",
        "      inputs = tf.keras.layers.Input(shape = (seq_len, 3))\n",
        "\n",
        "    embed = tf.keras.layers.Embedding(input_dim = len(token2int), output_dim = embed_dim)(inputs)\n",
        "    reshaped = tf.reshape(embed, shape = (-1, embed.shape[1], embed.shape[2] * embed.shape[3]))\n",
        "    reshaped = tf.keras.layers.SpatialDropout1D(dropout)(reshaped)\n",
        "    \n",
        "    x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, \n",
        "                                                          dropout = dropout, \n",
        "                                                          return_sequences = True, \n",
        "                                                          kernel_initializer = 'orthogonal'))(reshaped)\n",
        "    x = wave_block(x, 16, 3, 12)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(dropout)(x)\n",
        "    x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, \n",
        "                                                          dropout = dropout, \n",
        "                                                          return_sequences = True, \n",
        "                                                          kernel_initializer = 'orthogonal'))(x)\n",
        "    x = wave_block(x, 32, 3, 8)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(dropout)(x)\n",
        "    x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, \n",
        "                                                          dropout = dropout, \n",
        "                                                          return_sequences = True, \n",
        "                                                          kernel_initializer = 'orthogonal'))(x)\n",
        "    x = wave_block(x, 64, 3, 4)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(dropout)(x)\n",
        "    x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, \n",
        "                                                          dropout = dropout, \n",
        "                                                          return_sequences = True, \n",
        "                                                          kernel_initializer = 'orthogonal'))(x)\n",
        "\n",
        "    truncated = x[:, :pred_len]\n",
        "    out1 = tf.keras.layers.Dense(1024, activation='relu')(truncated)\n",
        "    out2 = tf.keras.layers.Dropout(0.4)(out1)\n",
        "    out = tf.keras.layers.Dense(5, activation = 'linear')(out2)\n",
        "    model = tf.keras.models.Model(inputs = inputs, outputs = out)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "    opt = tfa.optimizers.SWA(opt)\n",
        "    model.compile(optimizer = opt,\n",
        "                  loss = MCRMSE_3)\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaZjDFM463LY"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lautqRKb617N"
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "from keras import backend as K\n",
        "class CosineAnnealingScheduler(Callback):\n",
        "    \"\"\"Cosine annealing scheduler.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, T_max, eta_max, eta_min=0, verbose=0):\n",
        "        super(CosineAnnealingScheduler, self).__init__()\n",
        "        self.T_max = T_max\n",
        "        self.eta_max = eta_max\n",
        "        self.eta_min = eta_min\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        if not hasattr(self.model.optimizer, 'lr'):\n",
        "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
        "        lr = self.eta_min + (self.eta_max - self.eta_min) * (1 + math.cos(math.pi * epoch / self.T_max)) / 2\n",
        "        K.set_value(self.model.optimizer.lr, lr)\n",
        "        if self.verbose > 0:\n",
        "            print('\\nEpoch %05d: CosineAnnealingScheduler setting learning '\n",
        "                  'rate to %s.' % (epoch + 1, lr))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        logs['lr'] = K.get_value(self.model.optimizer.lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4E3s1Iiqe4J"
      },
      "source": [
        "## choices are: 0, 1, 2, 3, 4, 'wn'\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def training(model_type, Verbose, seed=101):\n",
        "  kmeans_model = KMeans(n_clusters=200, random_state=seed).fit(train_inputs[:,:,0])\n",
        "  train['cluster_id'] = kmeans_model.labels_\n",
        "  model_private_preds = np.zeros((private_df.shape[0], 130, 5))\n",
        "  model_public_preds = np.zeros((public_df.shape[0], 107, 5))\n",
        "  oof = []\n",
        "  labels = []\n",
        "  if model_type == 'wn':\n",
        "    name = 'wavenet'\n",
        "  elif model_type == 0:\n",
        "    name = 'gru'\n",
        "  elif model_type == 1:\n",
        "    name = 'lstm'\n",
        "  elif model_type == 2:\n",
        "    name = 'hybrid1'\n",
        "  elif model_type == 3:\n",
        "    name = 'hybrid2'\n",
        "  elif model_type == 4:\n",
        "    name = 'hybrid3'\n",
        "  print(f'Training 5-fold {name} now......')\n",
        "  histories = []\n",
        "  rskf = RepeatedStratifiedKFold(5, n_repeats = 1, random_state = 42)\n",
        "  gkf = GroupKFold(n_splits=5)\n",
        "  kf = rskf.split(train_inputs, train['SN_filter'])\n",
        "  for fold, (train_index, val_index) in enumerate(gkf.split(train_inputs, train['reactivity'], train['cluster_id'])):\n",
        "      train_ = train_inputs[train_index]\n",
        "      train_labs = train_labels[train_index]\n",
        "      val_ = train_inputs[val_index]\n",
        "      val_labs = train_labels[val_index]\n",
        "\n",
        "      # lr_callback = CosineAnnealingScheduler(T_max=100, eta_max=1e-3, eta_min=1e-8)\n",
        "\n",
        "      if model_type == 'wn':\n",
        "        model = build_wavenet_model()\n",
        "      else:\n",
        "        model = build_model(gru=model_type)\n",
        "\n",
        "      sv = tf.keras.callbacks.ModelCheckpoint(f'model_{name}_{fold}.h5')\n",
        "\n",
        "      history = model.fit(\n",
        "          train_, train_labs, \n",
        "          validation_data=(val_,val_labs),\n",
        "          batch_size=128,\n",
        "          epochs=200,\n",
        "          #callbacks=[lr_callback,sv],\n",
        "          callbacks=[tf.keras.callbacks.ReduceLROnPlateau(patience=10),sv],\n",
        "          verbose = Verbose\n",
        "      )\n",
        "      histories.append(history)\n",
        "      fold_loss = min(history.history['val_loss'])\n",
        "      print(f'Best Validation Loss for fold {fold} is {fold_loss}')\n",
        "\n",
        "      ## Calculate OOF\n",
        "      model.load_weights(f'model_{name}_{fold}.h5') # load the model\n",
        "      oof.append(model.predict(val_)) # append to oof\n",
        "      labels.append(val_labs)\n",
        "\n",
        "      if model_type == 'wn':\n",
        "        model_short = build_wavenet_model(seq_len=107, pred_len=107)\n",
        "        model_long = build_wavenet_model(seq_len=130, pred_len=130)\n",
        "      else:\n",
        "        model_short = build_model(gru=model_type, seq_len=107, pred_len=107)\n",
        "        model_long = build_model(gru=model_type, seq_len=130, pred_len=130)\n",
        "\n",
        "      model_short.load_weights(f'model_{name}_{fold}.h5')\n",
        "      model_public_pred = model_short.predict(public_inputs) / 5\n",
        "      \n",
        "      model_long.load_weights(f'model_{name}_{fold}.h5')\n",
        "      model_private_pred = model_long.predict(private_inputs) / 5 \n",
        "\n",
        "      model_public_preds += model_public_pred\n",
        "      model_private_preds += model_private_pred\n",
        "  \n",
        "  print(f\"Overall mean {name} MCRMSE: {np.mean([min(history.history['val_loss']) for history in histories])}\")\n",
        "  return oof, labels, model_public_preds, model_private_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wVMZOO9gTB1"
      },
      "source": [
        "## Wavenet Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBxowjzR2U5C",
        "outputId": "f6fa3956-466f-4232-d31b-fe6f7af83676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "oof_wn, labels_wn, wn_public_preds, wn_private_preds = training(model_type='wn', Verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training 5-fold wavenet now......\n",
            "Best Validation Loss for fold 0 is 0.2346225529909134\n",
            "Best Validation Loss for fold 1 is 0.2530500888824463\n",
            "Best Validation Loss for fold 2 is 0.24116666615009308\n",
            "Best Validation Loss for fold 3 is 0.248418390750885\n",
            "Best Validation Loss for fold 4 is 0.21891511976718903\n",
            "Overall wavenet MCRMSE: 0.23923456370830537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSpuqdoZKUl2"
      },
      "source": [
        "# preds_wn_df_seed1 = pd.concat(arrange_pred(wn_public_preds, wn_private_preds))\n",
        "# submission_seed1 = sample_sub[['id_seqpos']].merge(preds_wn_df, on=['id_seqpos'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwj8aWgjKZqO"
      },
      "source": [
        "preds_wn_df_seed2 = pd.concat(arrange_pred(wn_public_preds, wn_private_preds))\n",
        "submission_seed2 = sample_sub[['id_seqpos']].merge(preds_wn_df, on=['id_seqpos'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoG9yd8nVqI0"
      },
      "source": [
        "submission = submission_seed1.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjPUlZDaUx_B"
      },
      "source": [
        "submission.iloc[:, 1:] = submission_seed1.iloc[:, 1:] * .5 + submission_seed2.iloc[:, 1:] * .5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjYboaYPVDka"
      },
      "source": [
        "submission.to_csv('wavenet_2seeds_cv237.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUsa-9vQmEYJ"
      },
      "source": [
        "* 0.3386 Wavenet, patience = 7\n",
        "* 0.3450 Wavenet, patience = 7, dropout=0.2\n",
        "* 0.21360034, patience=7, original\n",
        "* 0.209356, patience=7, added another dense\n",
        "* 0.2085, patience=7, dense = 1024\n",
        "* 0.2079, patience=7, dense = 1024\n",
        "* 0.2075, patience=10, dense = 1024\n",
        "* 0.2074, patience=10, feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEE9q_nYnzv9"
      },
      "source": [
        "## GRU Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y-Bz5Y0ZEFK"
      },
      "source": [
        "def MCRMSE_3_(y_actual, y_pred):\n",
        "    score = 0\n",
        "    for i in [0,1,3]:\n",
        "        score += rmse(y_actual[:, :, i], y_pred[:, :, i]) / 3\n",
        "    return np.mean(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEtpB6RZaI5q"
      },
      "source": [
        "def arrange_pred(public_preds, private_preds):\n",
        "  preds_model = []\n",
        "  for df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n",
        "      for i, uid in enumerate(df.id):\n",
        "          single_pred = preds[i]\n",
        "          single_df = pd.DataFrame(single_pred, columns=target_cols)\n",
        "          single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
        "          preds_model.append(single_df)\n",
        "  return preds_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCZ_axNP93nG"
      },
      "source": [
        "final_sub = sample_sub.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuWgv3zA87IT",
        "outputId": "28809f56-8dc3-4d8a-e6ed-71d2789622d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "for i in [1,2,3,4,5]:\n",
        "  print(f'seed is {i}')\n",
        "  oof_gru, labels_gru, gru_public_preds, gru_private_preds = training(model_type=2, Verbose=0, seed=i)\n",
        "  oof_gru_overall = np.concatenate((oof_gru[0], oof_gru[1], oof_gru[2], oof_gru[3], oof_gru[4]))\n",
        "  ground_truth_label = np.concatenate((labels_gru[0], labels_gru[1], labels_gru[2], labels_gru[3], labels_gru[4]))\n",
        "  print(f'OVERALL loss is {MCRMSE_3_(ground_truth_label, oof_gru_overall)}')\n",
        "  preds_gru_df = pd.concat(arrange_pred(gru_public_preds, gru_private_preds))\n",
        "  submission = sample_sub[['id_seqpos']].merge(preds_gru_df, on=['id_seqpos'])\n",
        "  final_sub.iloc[:, 1:] += .2 * submission.iloc[:, 1:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seed is 1\n",
            "Training 5-fold hybrid1 now......\n",
            "Best Validation Loss for fold 0 is 0.25155872106552124\n",
            "Best Validation Loss for fold 1 is 0.22571605443954468\n",
            "Best Validation Loss for fold 2 is 0.25860220193862915\n",
            "Best Validation Loss for fold 3 is 0.2503390312194824\n",
            "Best Validation Loss for fold 4 is 0.2517712116241455\n",
            "Overall mean hybrid1 MCRMSE: 0.2475974440574646\n",
            "OVERALL loss is 0.24315397441387177\n",
            "seed is 2\n",
            "Training 5-fold hybrid1 now......\n",
            "Best Validation Loss for fold 0 is 0.2515604496002197\n",
            "Best Validation Loss for fold 1 is 0.26008865237236023\n",
            "Best Validation Loss for fold 2 is 0.23867502808570862\n",
            "Best Validation Loss for fold 3 is 0.24746820330619812\n",
            "Best Validation Loss for fold 4 is 0.28446507453918457\n",
            "Overall mean hybrid1 MCRMSE: 0.2564514815807343\n",
            "OVERALL loss is 0.25104594230651855\n",
            "seed is 3\n",
            "Training 5-fold hybrid1 now......\n",
            "Best Validation Loss for fold 0 is 0.25204551219940186\n",
            "Best Validation Loss for fold 1 is 0.23795200884342194\n",
            "Best Validation Loss for fold 2 is 0.2422875612974167\n",
            "Best Validation Loss for fold 3 is 0.25777649879455566\n",
            "Best Validation Loss for fold 4 is 0.24194669723510742\n",
            "Overall mean hybrid1 MCRMSE: 0.2464016556739807\n",
            "OVERALL loss is 0.2422766536474228\n",
            "seed is 4\n",
            "Training 5-fold hybrid1 now......\n",
            "Best Validation Loss for fold 0 is 0.24589896202087402\n",
            "Best Validation Loss for fold 1 is 0.24111507833003998\n",
            "Best Validation Loss for fold 2 is 0.26036062836647034\n",
            "Best Validation Loss for fold 3 is 0.2522799074649811\n",
            "Best Validation Loss for fold 4 is 0.27629804611206055\n",
            "Overall mean hybrid1 MCRMSE: 0.2551905244588852\n",
            "OVERALL loss is 0.24999283254146576\n",
            "seed is 5\n",
            "Training 5-fold hybrid1 now......\n",
            "Best Validation Loss for fold 0 is 0.24703118205070496\n",
            "Best Validation Loss for fold 1 is 0.25096675753593445\n",
            "Best Validation Loss for fold 2 is 0.25990837812423706\n",
            "Best Validation Loss for fold 3 is 0.25048866868019104\n",
            "Best Validation Loss for fold 4 is 0.24062205851078033\n",
            "Overall mean hybrid1 MCRMSE: 0.24980340898036957\n",
            "OVERALL loss is 0.24599693715572357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xERPbnjSAOla",
        "outputId": "5e75d26d-b2ca-4a81-e80f-8fee43531292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "final_sub.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_seqpos</th>\n",
              "      <th>reactivity</th>\n",
              "      <th>deg_Mg_pH10</th>\n",
              "      <th>deg_pH10</th>\n",
              "      <th>deg_Mg_50C</th>\n",
              "      <th>deg_50C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_00073f8be_0</td>\n",
              "      <td>0.637045</td>\n",
              "      <td>0.656401</td>\n",
              "      <td>2.042983</td>\n",
              "      <td>0.533870</td>\n",
              "      <td>0.748103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_00073f8be_1</td>\n",
              "      <td>1.983767</td>\n",
              "      <td>2.809911</td>\n",
              "      <td>3.978055</td>\n",
              "      <td>2.927414</td>\n",
              "      <td>2.659771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_00073f8be_2</td>\n",
              "      <td>1.360241</td>\n",
              "      <td>0.603129</td>\n",
              "      <td>0.723768</td>\n",
              "      <td>0.721851</td>\n",
              "      <td>0.794325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_00073f8be_3</td>\n",
              "      <td>1.278732</td>\n",
              "      <td>1.068196</td>\n",
              "      <td>1.157663</td>\n",
              "      <td>1.536598</td>\n",
              "      <td>1.550203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_00073f8be_4</td>\n",
              "      <td>0.857197</td>\n",
              "      <td>0.599222</td>\n",
              "      <td>0.586575</td>\n",
              "      <td>0.853780</td>\n",
              "      <td>0.826137</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C   deg_50C\n",
              "0  id_00073f8be_0    0.637045     0.656401  2.042983    0.533870  0.748103\n",
              "1  id_00073f8be_1    1.983767     2.809911  3.978055    2.927414  2.659771\n",
              "2  id_00073f8be_2    1.360241     0.603129  0.723768    0.721851  0.794325\n",
              "3  id_00073f8be_3    1.278732     1.068196  1.157663    1.536598  1.550203\n",
              "4  id_00073f8be_4    0.857197     0.599222  0.586575    0.853780  0.826137"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukk-GsOphaoP"
      },
      "source": [
        "final_sub.to_csv('5fold_5seed_cv245_lstm_only.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a44zMDXVauRx",
        "outputId": "036e5025-8a6e-4e3f-cf6d-7e4156c94fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# submit\n",
        "!kaggle competitions submit -c stanford-covid-vaccine -f 5fold_5seed_cv245_lstm_only.csv -m \"cv245\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 49.6M/49.6M [00:05<00:00, 9.59MB/s]\n",
            "Successfully submitted to OpenVaccine: COVID-19 mRNA Vaccine Degradation Prediction"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fhRrZVx6d3z"
      },
      "source": [
        "* 3415 patient=7\n",
        "* 2167 filtered\n",
        "* 2142 filtered with another dense512 + dropout0.4(best)\n",
        "* 2131 filtered with another dense1024 + dropout0.4(best)\n",
        "* 2103 filtered with another dense1024 + dropout0.4(best), patient=12\n",
        "* 2104 feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpxQcsXiojRD"
      },
      "source": [
        "## LSTM Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak89vhs6a9y1",
        "outputId": "809c520a-b473-4eaf-b39b-94f9943e4436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "oof_lstm, labels_lstm, lstm_public_preds, lstm_private_preds = training(model_type=1, Verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training 5-fold lstm now......\n",
            "Best Validation Loss for fold 0 is 0.25026124715805054\n",
            "Best Validation Loss for fold 1 is 0.2479071319103241\n",
            "Best Validation Loss for fold 2 is 0.2454013079404831\n",
            "Best Validation Loss for fold 3 is 0.24307531118392944\n",
            "Best Validation Loss for fold 4 is 0.2598634660243988\n",
            "Overall lstm MCRMSE: 0.2493016928434372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3fG8pkfGs1S"
      },
      "source": [
        "* 0.3925 ReduceLrOnPlateu\n",
        "* 0.218 dense 512\n",
        "* 0.216 dense 1024\n",
        "* 0.2155 feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Vr0rFRhpv7m"
      },
      "source": [
        "## Hybrid Training 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XHDEswQbDry",
        "outputId": "3f626cf5-cb6f-4655-8181-6ddaa965805b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "oof_hyd1, labels_hyd1, hyd1_public_preds, hyd1_private_preds = training(model_type=2, Verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training 5-fold hybrid1 now......\n",
            "Best Validation Loss for fold 0 is 0.24281279742717743\n",
            "Best Validation Loss for fold 1 is 0.24454864859580994\n",
            "Best Validation Loss for fold 2 is 0.2439412772655487\n",
            "Best Validation Loss for fold 3 is 0.2362826019525528\n",
            "Best Validation Loss for fold 4 is 0.2576320171356201\n",
            "Overall hybrid1 MCRMSE: 0.2450434684753418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsWcwondRVEm"
      },
      "source": [
        "0.21655\n",
        "\n",
        "0.2141"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIWN5ISEqZuK"
      },
      "source": [
        "## Hybrid Training 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHdP1ANvbEQm",
        "outputId": "81440a55-3943-4373-bc41-bb0fa006803d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "oof_hyd2, labels_hyd2, hyd2_public_preds, hyd2_private_preds = training(model_type=3, Verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training 5-fold hybrid2 now......\n",
            "Best Validation Loss for fold 0 is 0.24593289196491241\n",
            "Best Validation Loss for fold 1 is 0.23983217775821686\n",
            "Best Validation Loss for fold 2 is 0.2403288036584854\n",
            "Best Validation Loss for fold 3 is 0.23508141934871674\n",
            "Best Validation Loss for fold 4 is 0.25233274698257446\n",
            "Overall hybrid2 MCRMSE: 0.24270160794258117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jektdp-XRN32"
      },
      "source": [
        "* 0.213325 512\n",
        "* 0.21236 1024\n",
        "* 0.210 patience = 12 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM74TK5_5r5a"
      },
      "source": [
        "## Hybrid Training 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Jf_x9V8qYZe",
        "outputId": "87b3d7e8-5750-4fc0-a2d4-85db9e9340da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "oof_hyd3, labels_hyd3, hyd3_public_preds, hyd3_private_preds = training(model_type=4, Verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training 5-fold hybrid3 now......\n",
            "Best Validation Loss for fold 0 is 0.2532396912574768\n",
            "Best Validation Loss for fold 1 is 0.24669629335403442\n",
            "Best Validation Loss for fold 2 is 0.24496805667877197\n",
            "Best Validation Loss for fold 3 is 0.24376976490020752\n",
            "Best Validation Loss for fold 4 is 0.26051726937294006\n",
            "Overall hybrid3 MCRMSE: 0.24983821511268617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Jf_iPTbRQRW"
      },
      "source": [
        "* 0.220336\n",
        "* 0.21945\n",
        "* 0.2193"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPbyoHqKmlqh"
      },
      "source": [
        "## OOF Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT8aNEAZNZ4c"
      },
      "source": [
        "if filter:\n",
        "  oof_wn_overall = np.concatenate((oof_wn[0], oof_wn[1], oof_wn[2], oof_wn[3], oof_wn[4]))\n",
        "  oof_gru_overall = np.concatenate((oof_gru[0], oof_gru[1], oof_gru[2], oof_gru[3], oof_gru[4]))\n",
        "  oof_lstm_overall = np.concatenate((oof_lstm[0], oof_lstm[1], oof_lstm[2], oof_lstm[3], oof_lstm[4]))\n",
        "  oof_hyd1_overall = np.concatenate((oof_hyd1[0], oof_hyd1[1], oof_hyd1[2], oof_hyd1[3], oof_hyd1[4]))\n",
        "  oof_hyd2_overall = np.concatenate((oof_hyd2[0], oof_hyd2[1], oof_hyd2[2], oof_hyd2[3], oof_hyd2[4]))\n",
        "  oof_hyd3_overall = np.concatenate((oof_hyd3[0], oof_hyd3[1], oof_hyd3[2], oof_hyd3[3], oof_hyd3[4]))\n",
        "  ground_truth_label = np.concatenate((labels_wn[0], labels_wn[1], labels_wn[2], labels_wn[3], labels_wn[4]))\n",
        "else:\n",
        "  oof_wn_overall = np.array(oof_wn).reshape(-1, 68, 5)\n",
        "  oof_gru_overall = np.array(oof_gru).reshape(-1, 68, 5)\n",
        "  oof_lstm_overall = np.array(oof_lstm).reshape(-1, 68, 5)\n",
        "  oof_hyd1_overall = np.array(oof_hyd1).reshape(-1, 68, 5)\n",
        "  oof_hyd2_overall = np.array(oof_hyd2).reshape(-1, 68, 5)\n",
        "  oof_hyd3_overall = np.array(oof_hyd3).reshape(-1, 68, 5)\n",
        "  ground_truth_label = np.array(labels_wn).reshape(-1, 68, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qohc_FpkVC3L"
      },
      "source": [
        "def MCRMSE_(y_actual, y_pred):\n",
        "    score = 0\n",
        "    for i in range(5):\n",
        "        score += rmse(y_actual[:, :, i], y_pred[:, :, i]) / 5\n",
        "    return np.mean(score)\n",
        "\n",
        "def MCRMSE_3(y_actual, y_pred):\n",
        "    score = 0\n",
        "    for i in [0,1,3]:\n",
        "        score += rmse(y_actual[:, :, i], y_pred[:, :, i]) / 3\n",
        "    return np.mean(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ncn-T8MBQoCV",
        "outputId": "b2772425-f558-423f-b1a0-7b527baa7feb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "for index, i in enumerate([oof_wn_overall, oof_gru_overall, oof_lstm_overall, oof_hyd1_overall, oof_hyd2_overall, oof_hyd3_overall]):\n",
        "  print(f'{index+1}. ', MCRMSE_3(ground_truth_label, i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.  0.24083109\n",
            "2.  0.24245878\n",
            "3.  0.25006413\n",
            "4.  0.2460459\n",
            "5.  0.24346918\n",
            "6.  0.25051346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA5Haalou_Z7"
      },
      "source": [
        "## output oof\n",
        "\n",
        "np.save('/content/drive/My Drive/open_vaccine_data_added_fe/oof_wn_fe.npy', oof_wn_overall)\n",
        "np.save('/content/drive/My Drive/open_vaccine_data_added_fe/oof_gru_fe.npy', oof_gru_overall)\n",
        "np.save('/content/drive/My Drive/open_vaccine_data_added_fe/oof_lstm_fe.npy', oof_lstm_overall)\n",
        "np.save('/content/drive/My Drive/open_vaccine_data_added_fe/oof_hyd1_fe.npy', oof_hyd1_overall)\n",
        "np.save('/content/drive/My Drive/open_vaccine_data_added_fe/oof_hyd2_fe.npy', oof_hyd2_overall)\n",
        "np.save('/content/drive/My Drive/open_vaccine_data_added_fe/oof_hyd3_fe.npy', oof_hyd3_overall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEfK96XFzODw"
      },
      "source": [
        "# np.save('ground_truth_label.npy', ground_truth_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMlr0OFwYfo7"
      },
      "source": [
        "def func_numpy_metric(weights):\n",
        "    w1, w2, w3, w4, w5, w6 = weights\n",
        "    oof_blend = w1 * oof_wn_overall + w2 * oof_gru_overall + w3 * oof_lstm_overall + w4 * oof_hyd1_overall + w5 * oof_hyd2_overall + w6 * oof_hyd3_overall\n",
        "    score = MCRMSE_3(ground_truth_label, oof_blend)\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnbhrs6TaJE-",
        "outputId": "01c3180b-d55b-45e1-9031-7c2f091ad95c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print('\\n Finding Blending Weights ...')\n",
        "from tqdm import tqdm\n",
        "res_list = []\n",
        "weights_list = []\n",
        "\n",
        "for k in tqdm(range(1000)):\n",
        "    a = np.random.randint(0, 100, 6)\n",
        "    starting_values = a / np.sum(a)\n",
        "    bounds = [(0, 1)] * 6\n",
        "    \n",
        "    res = minimize(func_numpy_metric,\n",
        "                   starting_values,\n",
        "                   method='L-BFGS-B',\n",
        "                   bounds=bounds,\n",
        "                   options={'disp': False,\n",
        "                            'maxiter': 100000}) \n",
        "    \n",
        "    res_list.append(res['fun'])\n",
        "    weights_list.append(res['x'])\n",
        "    \n",
        "bestSC   = np.min(res_list)\n",
        "bestWght = weights_list[np.argmin(res_list)]\n",
        "weights  = bestWght\n",
        "blend_score = round(bestSC, 6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/1000 [00:00<02:19,  7.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Finding Blending Weights ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 1000/1000 [08:20<00:00,  2.00it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgURzCMXaiXJ",
        "outputId": "1d8b9dad-1f50-491b-e24e-8acb7a631b18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print('\\n Ensemble Score: {best_score}'.format(best_score=bestSC))\n",
        "print('\\n Best Weights: {weights}'.format(weights=bestWght))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Ensemble Score: 0.23115622997283936\n",
            "\n",
            " Best Weights: [0.309375   0.25625    0.084375   0.153125   0.109375   0.08306165]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvrvZbHCG5lY",
        "outputId": "2c8eb8ed-b924-43bf-e45b-09374dbb7c82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sum(weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9955616549199191"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xds8vDYqmojD"
      },
      "source": [
        "## Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrnDHpc7pF1j"
      },
      "source": [
        "def arrange_pred(public_preds, private_preds):\n",
        "  preds_model = []\n",
        "  for df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n",
        "      for i, uid in enumerate(df.id):\n",
        "          single_pred = preds[i]\n",
        "          single_df = pd.DataFrame(single_pred, columns=target_cols)\n",
        "          single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
        "          preds_model.append(single_df)\n",
        "  return preds_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xsU_YLi1rvJ"
      },
      "source": [
        "preds_wn_df = pd.concat(arrange_pred(wn_public_preds, wn_private_preds))\n",
        "preds_gru_df = pd.concat(arrange_pred(gru_public_preds, gru_private_preds))\n",
        "preds_lstm_df = pd.concat(arrange_pred(lstm_public_preds, lstm_private_preds))\n",
        "preds_hyd1_df = pd.concat(arrange_pred(hyd1_public_preds, hyd1_private_preds))\n",
        "preds_hyd2_df = pd.concat(arrange_pred(hyd2_public_preds, hyd2_private_preds))\n",
        "preds_hyd3_df = pd.concat(arrange_pred(hyd3_public_preds, hyd3_private_preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2iR94vGfOGm"
      },
      "source": [
        "weights = weights / np.sum(weights) # making sure it's 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhzelMJdwIoA"
      },
      "source": [
        "blend_preds_df = preds_hyd3_df.copy()\n",
        "blend_preds_df.iloc[:, :-1] = 0\n",
        "for index, i in enumerate([preds_wn_df, preds_gru_df, preds_lstm_df, preds_hyd1_df, preds_hyd2_df, preds_hyd3_df]):\n",
        "  blend_preds_df.iloc[:, :-1] += i.iloc[:,:-1] * weights[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSQQ1BKlxZTA",
        "outputId": "c6b79dc7-25d9-4685-fe11-be4b8e19e087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "blend_preds_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reactivity</th>\n",
              "      <th>deg_Mg_pH10</th>\n",
              "      <th>deg_pH10</th>\n",
              "      <th>deg_Mg_50C</th>\n",
              "      <th>deg_50C</th>\n",
              "      <th>id_seqpos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.688670</td>\n",
              "      <td>0.652019</td>\n",
              "      <td>-0.020325</td>\n",
              "      <td>0.548482</td>\n",
              "      <td>0.042420</td>\n",
              "      <td>id_00073f8be_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.138515</td>\n",
              "      <td>2.948593</td>\n",
              "      <td>0.023414</td>\n",
              "      <td>3.085091</td>\n",
              "      <td>0.040201</td>\n",
              "      <td>id_00073f8be_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.444244</td>\n",
              "      <td>0.622930</td>\n",
              "      <td>0.036847</td>\n",
              "      <td>0.744493</td>\n",
              "      <td>0.039590</td>\n",
              "      <td>id_00073f8be_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.257418</td>\n",
              "      <td>1.064093</td>\n",
              "      <td>-0.008306</td>\n",
              "      <td>1.532421</td>\n",
              "      <td>0.075368</td>\n",
              "      <td>id_00073f8be_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.854573</td>\n",
              "      <td>0.596857</td>\n",
              "      <td>-0.006440</td>\n",
              "      <td>0.851687</td>\n",
              "      <td>0.026148</td>\n",
              "      <td>id_00073f8be_4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C   deg_50C       id_seqpos\n",
              "0    0.688670     0.652019 -0.020325    0.548482  0.042420  id_00073f8be_0\n",
              "1    2.138515     2.948593  0.023414    3.085091  0.040201  id_00073f8be_1\n",
              "2    1.444244     0.622930  0.036847    0.744493  0.039590  id_00073f8be_2\n",
              "3    1.257418     1.064093 -0.008306    1.532421  0.075368  id_00073f8be_3\n",
              "4    0.854573     0.596857 -0.006440    0.851687  0.026148  id_00073f8be_4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V52wwwHvxy-"
      },
      "source": [
        "submission = sample_sub[['id_seqpos']].merge(blend_preds_df, on=['id_seqpos'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeeidvVAxhhc"
      },
      "source": [
        "submission.to_csv('/content/drive/My Drive/open_vaccine_data_added_fe/sub_fe_new_cv.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_r2_ApYm_0a"
      },
      "source": [
        "submission.to_csv('sub_fe.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSS8mKZvWPHI",
        "outputId": "fcda6582-908d-499f-e0a2-5da0bb0eee6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# submit\n",
        "!kaggle competitions submit -c stanford-covid-vaccine -f wavenet_2seeds_cv237.csv -m \"cv237\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 50.8M/50.8M [00:04<00:00, 11.6MB/s]\n",
            "Successfully submitted to OpenVaccine: COVID-19 mRNA Vaccine Degradation Prediction"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKAGpXZwHOVU",
        "outputId": "08ebf914-c046-4729-d534-9c49fc7039d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reactivity</th>\n",
              "      <th>deg_Mg_pH10</th>\n",
              "      <th>deg_pH10</th>\n",
              "      <th>deg_Mg_50C</th>\n",
              "      <th>deg_50C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.763814</td>\n",
              "      <td>0.692169</td>\n",
              "      <td>0.069476</td>\n",
              "      <td>0.576933</td>\n",
              "      <td>-0.094168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.381897</td>\n",
              "      <td>3.314302</td>\n",
              "      <td>-0.035656</td>\n",
              "      <td>3.318505</td>\n",
              "      <td>-0.389209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.534115</td>\n",
              "      <td>0.624643</td>\n",
              "      <td>-0.118847</td>\n",
              "      <td>0.732306</td>\n",
              "      <td>-0.033215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.322329</td>\n",
              "      <td>1.162570</td>\n",
              "      <td>-0.043088</td>\n",
              "      <td>1.683879</td>\n",
              "      <td>-0.111748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.844963</td>\n",
              "      <td>0.592926</td>\n",
              "      <td>-0.008817</td>\n",
              "      <td>0.852003</td>\n",
              "      <td>-0.097187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457948</th>\n",
              "      <td>0.496888</td>\n",
              "      <td>0.667506</td>\n",
              "      <td>0.084097</td>\n",
              "      <td>0.965359</td>\n",
              "      <td>-0.050289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457949</th>\n",
              "      <td>0.706034</td>\n",
              "      <td>1.056895</td>\n",
              "      <td>0.118600</td>\n",
              "      <td>1.342684</td>\n",
              "      <td>-0.011633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457950</th>\n",
              "      <td>0.829533</td>\n",
              "      <td>0.390117</td>\n",
              "      <td>0.094393</td>\n",
              "      <td>0.733908</td>\n",
              "      <td>-0.008469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457951</th>\n",
              "      <td>0.467425</td>\n",
              "      <td>0.433830</td>\n",
              "      <td>0.099879</td>\n",
              "      <td>0.715381</td>\n",
              "      <td>-0.021365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457952</th>\n",
              "      <td>0.308385</td>\n",
              "      <td>0.731212</td>\n",
              "      <td>0.067441</td>\n",
              "      <td>0.981408</td>\n",
              "      <td>-0.029463</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>457953 rows  5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C   deg_50C\n",
              "0         0.763814     0.692169  0.069476    0.576933 -0.094168\n",
              "1         2.381897     3.314302 -0.035656    3.318505 -0.389209\n",
              "2         1.534115     0.624643 -0.118847    0.732306 -0.033215\n",
              "3         1.322329     1.162570 -0.043088    1.683879 -0.111748\n",
              "4         0.844963     0.592926 -0.008817    0.852003 -0.097187\n",
              "...            ...          ...       ...         ...       ...\n",
              "457948    0.496888     0.667506  0.084097    0.965359 -0.050289\n",
              "457949    0.706034     1.056895  0.118600    1.342684 -0.011633\n",
              "457950    0.829533     0.390117  0.094393    0.733908 -0.008469\n",
              "457951    0.467425     0.433830  0.099879    0.715381 -0.021365\n",
              "457952    0.308385     0.731212  0.067441    0.981408 -0.029463\n",
              "\n",
              "[457953 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3ezcOKxVg6F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}